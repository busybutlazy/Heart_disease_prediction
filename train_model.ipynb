{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "project_path=Path.cwd().joinpath(\"project1/Heart_disease_prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/busybutlazy/project1/Heart_disease_prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/busybutlazy/miniconda3/envs/heart_diease/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd project1/Heart_disease_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = pd.read_csv(project_path.joinpath(\"dataset/cleaned_merged_heart_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalachh  exang  oldpeak  \\\n",
       "0   63    1   3       145   233    1        0       150      0      2.3   \n",
       "1   37    1   2       130   250    0        1       187      0      3.5   \n",
       "2   41    0   1       130   204    0        0       172      0      1.4   \n",
       "3   56    1   1       120   236    0        1       178      0      0.8   \n",
       "4   57    0   0       120   354    0        1       163      1      0.6   \n",
       "\n",
       "   slope  ca  thal  target  \n",
       "0      0   0     1       1  \n",
       "1      0   0     2       1  \n",
       "2      2   0     2       1  \n",
       "3      2   0     2       1  \n",
       "4      2   0     2       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1888, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalachh',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "column_names = heart_data.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader , TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=heart_data[column_names[:-1]].values,heart_data[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 63. ,   1. ,   3. , 145. , 233. ,   1. ,   0. , 150. ,   0. ,\n",
       "          2.3,   0. ,   0. ,   1. ],\n",
       "       [ 37. ,   1. ,   2. , 130. , 250. ,   0. ,   1. , 187. ,   0. ,\n",
       "          3.5,   0. ,   0. ,   2. ],\n",
       "       [ 41. ,   0. ,   1. , 130. , 204. ,   0. ,   0. , 172. ,   0. ,\n",
       "          1.4,   2. ,   0. ,   2. ],\n",
       "       [ 56. ,   1. ,   1. , 120. , 236. ,   0. ,   1. , 178. ,   0. ,\n",
       "          0.8,   2. ,   0. ,   2. ],\n",
       "       [ 57. ,   0. ,   0. , 120. , 354. ,   0. ,   1. , 163. ,   1. ,\n",
       "          0.6,   2. ,   0. ,   2. ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar=StandardScaler()\n",
    "X_train=scalar.fit_transform(X_train)\n",
    "X_test=scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor=torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test_tensor=torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train_tensor=torch.tensor(y_train,dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor=torch.tensor(y_test,dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to deviece\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor=X_train_tensor.to(device)\n",
    "X_test_tensor=X_test_tensor.to(device)\n",
    "y_train_tensor=y_train_tensor.to(device)\n",
    "y_test_tensor=y_test_tensor.to(device)\n",
    "print(\"to deviece\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=16\n",
    "# train_dataset=TensorDataset(X_train_tensor,y_train_tensor)\n",
    "# train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(MLPModel,self).__init__()\n",
    "        self.fc1=nn.Linear(input_size,hidden_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2=nn.Linear(hidden_size,hidden_size)\n",
    "        self.fc3=nn.Linear(hidden_size,hidden_size)\n",
    "        self.fc4=nn.Linear(hidden_size,output_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc3(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc4(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=X_train.shape[1]\n",
    "hidden_size=20\n",
    "output_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPModel(\n",
       "  (fc1): Linear(in_features=13, out_features=20, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (fc4): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPModel(input_size=input_size,hidden_size=hidden_size,output_size=output_size)\n",
    "model=model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs=100000\n",
    "# for epoch in range(num_epochs):\n",
    "#     epoch_loss = 0.0\n",
    "#     for batch_idx,(inputs,targets) in enumerate(train_loader):\n",
    "#         # inputs , targets = inputs.to(device),targets.to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         loss=criterion(outputs,targets)    \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     if (epoch+1)%1000==0:\n",
    "#         avg_loss = epoch_loss / len(train_loader)\n",
    "#         print(f\"Epoch[{epoch+1}/{num_epochs},Loss:{loss.item():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5000/100000,Loss:0.0023]\n",
      "Epoch[10000/100000,Loss:0.0022]\n",
      "Epoch[15000/100000,Loss:0.0021]\n",
      "Epoch[20000/100000,Loss:0.0020]\n",
      "Epoch[25000/100000,Loss:0.0020]\n",
      "Epoch[30000/100000,Loss:0.0019]\n",
      "Epoch[35000/100000,Loss:0.0018]\n",
      "Epoch[40000/100000,Loss:0.0017]\n",
      "Epoch[45000/100000,Loss:0.0017]\n",
      "Epoch[50000/100000,Loss:0.0016]\n",
      "Epoch[55000/100000,Loss:0.0015]\n",
      "Epoch[60000/100000,Loss:0.0015]\n",
      "Epoch[65000/100000,Loss:0.0014]\n",
      "Epoch[70000/100000,Loss:0.0014]\n",
      "Epoch[75000/100000,Loss:0.0013]\n",
      "Epoch[80000/100000,Loss:0.0013]\n",
      "Epoch[85000/100000,Loss:0.0013]\n",
      "Epoch[90000/100000,Loss:0.0012]\n",
      "Epoch[95000/100000,Loss:0.0012]\n",
      "Epoch[100000/100000,Loss:0.0012]\n"
     ]
    }
   ],
   "source": [
    "num_epochs=100000\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion (outputs,y_train_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1)%5000==0:\n",
    "        print(f\"Epoch[{epoch+1}/{num_epochs},Loss:{loss.item():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 0.9497354030609131\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_pred = model(X_test_tensor)\n",
    "    y_pred_label = (torch.sigmoid(y_pred)>0.5).float()\n",
    "    accuracy = (y_pred_label == y_test_tensor).float().mean()\n",
    "    print(f\"Test accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'pretrained_model_ver2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
